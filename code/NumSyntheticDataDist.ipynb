{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from a CSV file\n",
    "def load_data(filename):\n",
    "\n",
    "    # Read the CSV file\n",
    "    data = pd.read_csv(filename)\n",
    "    # Drop the first column\n",
    "    data = data.drop(data.columns[0], axis=1)\n",
    "    # Drop the specified columns to get only numerical data\n",
    "    nums = data.drop(['subject_id', 'hadm_id', 'charttime'], axis=1)\n",
    "\n",
    "    return nums\n",
    "\n",
    "# Calculate mean, variance, and NaN counts for each column\n",
    "def calculate_stats(data):\n",
    "    nan_counts = data.isnull().sum()\n",
    "    smean = data.mean()\n",
    "    svar = data.var()\n",
    "    \n",
    "    return nan_counts, smean, svar\n",
    "\n",
    "# Fit different distributions to the data and select the best fit\n",
    "def fit_distributions(data):\n",
    "    # Define the distributions to be tested\n",
    "    distributions = {\n",
    "        'norm': stats.norm,\n",
    "        'lognorm': stats.lognorm,\n",
    "        'expon': stats.expon,\n",
    "        'gamma': stats.gamma,\n",
    "        'beta': stats.beta,\n",
    "        'weibull_min': stats.weibull_min,\n",
    "        't': stats.t,\n",
    "        'f': stats.f,\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    test_results = {}\n",
    "    for column in data.columns:\n",
    "        column_data = data[column].dropna()\n",
    "        _, smean, svar = calculate_stats(column_data)  # Extract only mean and variance\n",
    "        \n",
    "        best_fit = None\n",
    "        best_p_value = -1\n",
    "        test_result = []\n",
    "        \n",
    "        for name, distribution in distributions.items():\n",
    "            try:\n",
    "                if name in ['lognorm', 'gamma', 'beta', 'weibull_min', 't', 'chi2', 'f', 'pareto']:\n",
    "                    params = distribution.fit(column_data)\n",
    "                    ks_stat, p_value = stats.kstest(column_data, name, args=params)\n",
    "                else:\n",
    "                    params = distribution.fit(column_data)\n",
    "                    ks_stat, p_value = stats.kstest(column_data, name, args=params)\n",
    "                \n",
    "                test_result.append((name, ks_stat, p_value))\n",
    "                \n",
    "                if p_value > best_p_value:\n",
    "                    best_fit = (name, params)\n",
    "                    best_p_value = p_value\n",
    "            except Exception as e:\n",
    "                print(f\"Could not fit {name} distribution to {column}: {e}\")\n",
    "        \n",
    "        results[column] = best_fit\n",
    "        test_results[column] = test_result\n",
    "    \n",
    "    return results, test_results\n",
    "\n",
    "# Generate synthetic data based on the best-fitting distributions\n",
    "def generate_synthetic_data(data, fits):\n",
    "    samples = len(data)\n",
    "    synth_data = pd.DataFrame()\n",
    "    \n",
    "    for column in data.columns:\n",
    "        dist_name, params = fits[column]\n",
    "        distribution = getattr(stats, dist_name)\n",
    "        synthetic_data = distribution.rvs(*params[:-2], loc=params[-2], scale=params[-1], size=samples)\n",
    "        \n",
    "        # Ensure all values are non-negative and cap GCS_Total at 15\n",
    "        synthetic_data = np.clip(synthetic_data, a_min=0, a_max=None)\n",
    "        if column == 'GCS Total':\n",
    "            synthetic_data = np.clip(synthetic_data, a_min=0, a_max=15)\n",
    "        \n",
    "        # Introduce NaNs based on the original NaN distribution\n",
    "        nan_counts = data[column].isnull().sum()\n",
    "        nan_indices = np.random.choice(samples, nan_counts, replace=False)\n",
    "        synthetic_data[nan_indices] = np.nan\n",
    "        \n",
    "        synth_data[column] = synthetic_data\n",
    "    \n",
    "    return synth_data\n",
    "\n",
    "# Process a file and generate synthetic data\n",
    "def process_file(filename):\n",
    "    data = load_data(filename)\n",
    "    fits, test_results = fit_distributions(data)\n",
    "    synth_data = generate_synthetic_data(data, fits)\n",
    "\n",
    "    return data, synth_data, test_results\n",
    "\n",
    "# Compare statistics of real and synthetic data\n",
    "def compare_stats(real_data, synth_data):\n",
    "    real_nan_counts, real_mean, real_var = calculate_stats(real_data)\n",
    "    synth_nan_counts, synth_mean, synth_var = calculate_stats(synth_data)\n",
    "    \n",
    "    print(\"Comparison of Real and Synthetic Data:\\n\")\n",
    "    \n",
    "    for column in real_data.columns:\n",
    "        print(f\"Column: {column}\")\n",
    "        \n",
    "        print(f\"Real Mean: {real_mean[column]}\")\n",
    "        print(f\"Synthetic Mean: {synth_mean[column]}\")\n",
    "        print(f\"Mean Difference: {real_mean[column] - synth_mean[column]}\\n\")\n",
    "        \n",
    "        print(f\"Real Variance: {real_var[column]}\")\n",
    "        print(f\"Synthetic Variance: {synth_var[column]}\")\n",
    "        print(f\"Variance Difference: {real_var[column] - synth_var[column]}\\n\")\n",
    "        \n",
    "        print(f\"Real NaN Count: {real_nan_counts[column]}\")\n",
    "        print(f\"Synthetic NaN Count: {synth_nan_counts[column]}\")\n",
    "        print(f\"NaN Count Difference: {real_nan_counts[column] - synth_nan_counts[column]}\\n\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Print the results of the distribution tests and the best choice\n",
    "def print_test_results(test_results):\n",
    "    for column, results in test_results.items():\n",
    "        print(f\"Column: {column}\")\n",
    "        for name, ks_stat, p_value in results:\n",
    "            print(f\"Distribution: {name}, KS Statistic: {ks_stat}, P-Value: {p_value}\")\n",
    "        \n",
    "        # Determine the best fit\n",
    "        best_fit = max(results, key=lambda item: item[2])\n",
    "        print(f\"Best Fit: {best_fit[0]}, KS Statistic: {best_fit[1]}, P-Value: {best_fit[2]}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Njula Chakaya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2789: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  Lhat = muhat - Shat*mu\n",
      "c:\\Users\\Njula Chakaya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_minpack_py.py:178: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "c:\\Users\\Njula Chakaya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_continuous_distns.py:709: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sk = 2*(b-a)*np.sqrt(a + b + 1) / (a + b + 2) / np.sqrt(a*b)\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Using the earliest chart time for each hadm_id\n",
    "real_data_op1, synth_data_op1, test_results_op1 = process_file('NumOp1.csv')\n",
    "\n",
    "#synth_data_op1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_test_results(test_results_op1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare_stats(real_data_op1, synth_data_op1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Njula Chakaya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2789: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  Lhat = muhat - Shat*mu\n",
      "c:\\Users\\Njula Chakaya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_continuous_distns.py:709: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sk = 2*(b-a)*np.sqrt(a + b + 1) / (a + b + 2) / np.sqrt(a*b)\n",
      "c:\\Users\\Njula Chakaya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_minpack_py.py:178: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last five Jacobian evaluations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "c:\\Users\\Njula Chakaya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_minpack_py.py:178: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Picking the charttime with the fewest NaNs\n",
    "real_data_op2, synth_data_op2, test_results_op2 = process_file('NumOp2.csv')\n",
    "\n",
    "#synth_data_op2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_test_results(test_results_op2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare_stats(real_data_op2, synth_data_op2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Njula Chakaya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2789: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  Lhat = muhat - Shat*mu\n",
      "c:\\Users\\Njula Chakaya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_minpack_py.py:178: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "c:\\Users\\Njula Chakaya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_continuous_distns.py:709: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sk = 2*(b-a)*np.sqrt(a + b + 1) / (a + b + 2) / np.sqrt(a*b)\n"
     ]
    }
   ],
   "source": [
    "# Option 3: Picking the first reading within the hour (from the start of the first recorded time)\n",
    "\n",
    "real_data_op3, synth_data_op3, test_results_op3 = process_file('NumOp3.csv')\n",
    "\n",
    "#synth_data_op3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_test_results(test_results_op3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare_stats(real_data_op3, synth_data_op3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
